{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a7b3adf-ebaa-49df-a7ee-1d8129157c51",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0c8d9669-ca0e-497e-be62-cc8954a62a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "from kmodes.kmodes import KModes\n",
    "\n",
    "from sklearn.metrics import fowlkes_mallows_score, adjusted_rand_score, normalized_mutual_info_score\n",
    "from sklearn.metrics.cluster import adjusted_rand_score, normalized_mutual_info_score\n",
    "from sklearn.metrics import fowlkes_mallows_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "class BernoulliMixtureSEM:\n",
    "    \n",
    "    def __init__(self, n_components, max_iter, batch_size=100, tol=1e-3):\n",
    "        self.n_components = n_components\n",
    "        self.max_iter = max_iter\n",
    "        self.batch_size = batch_size\n",
    "        self.tol = tol\n",
    "    \n",
    "    def fit(self, x):\n",
    "        self.x = x\n",
    "        self.init_params()\n",
    "        log_bernoullis = self.get_log_bernoullis(self.x)\n",
    "        self.old_logL = self.get_log_likelihood(log_bernoullis)\n",
    "        for step in range(self.max_iter):\n",
    "            if step > 0:\n",
    "                self.old_logL = self.logL\n",
    "            self.gamma = self.get_responsibilities(log_bernoullis)\n",
    "            self.remember_params()\n",
    "            self.get_Neff()\n",
    "            self.get_mu(self.x)\n",
    "            self.get_pi()\n",
    "            log_bernoullis = self.get_log_bernoullis(self.x)\n",
    "            self.logL = self.get_log_likelihood(log_bernoullis)\n",
    "            if np.isnan(self.logL):\n",
    "                self.reset_params()\n",
    "                print(self.logL)\n",
    "                break\n",
    "\n",
    "    def iterate_batches(self):\n",
    "        n_samples = len(self.x)\n",
    "        indices = np.arange(n_samples)\n",
    "        np.random.shuffle(indices)\n",
    "        for start_idx in range(0, n_samples, self.batch_size):\n",
    "            end_idx = min(start_idx + self.batch_size, n_samples)\n",
    "            batch_indices = indices[start_idx:end_idx]\n",
    "            yield self.x.iloc[batch_indices]\n",
    "\n",
    "    def reset_params(self):\n",
    "        self.mu = self.old_mu.copy()\n",
    "        self.pi = self.old_pi.copy()\n",
    "        self.gamma = self.old_gamma.copy()\n",
    "        self.get_Neff()\n",
    "        log_bernoullis = self.get_log_bernoullis(self.x)\n",
    "        self.logL = self.get_log_likelihood(log_bernoullis)\n",
    "        \n",
    "    def remember_params(self):\n",
    "        self.old_mu = self.mu.copy()\n",
    "        self.old_pi = self.pi.copy()\n",
    "        self.old_gamma = self.gamma.copy()\n",
    "    \n",
    "    def init_params(self):\n",
    "        self.n_samples = self.x.shape[0]\n",
    "        self.n_features = self.x.shape[1]\n",
    "        self.pi = 1/self.n_components * np.ones(self.n_components)\n",
    "        self.mu = np.random.RandomState(seed=0).uniform(low=0.25, high=0.75, size=(self.n_components, self.n_features))\n",
    "        self.normalize_mu()\n",
    "        self.old_mu = None\n",
    "        self.old_pi = None\n",
    "        self.old_gamma = None\n",
    "    \n",
    "    def normalize_mu(self):\n",
    "        sum_over_features = np.sum(self.mu, axis=1)\n",
    "        for k in range(self.n_components):\n",
    "            self.mu[k,:] /= sum_over_features[k]\n",
    "            \n",
    "    def get_responsibilities(self, log_bernoullis):\n",
    "        gamma = np.zeros(shape=(log_bernoullis.shape[0], self.n_components))\n",
    "        Z =  logsumexp(np.log(self.pi[None,:]) + log_bernoullis, axis=1)\n",
    "        for k in range(self.n_components):\n",
    "            gamma[:, k] = np.exp(np.log(self.pi[k]) + log_bernoullis[:,k] - Z)\n",
    "        return gamma\n",
    "        \n",
    "    def get_log_bernoullis(self, x):\n",
    "        log_bernoullis = self.get_save_single(x, self.mu)\n",
    "        log_bernoullis += self.get_save_single(1-x, 1-self.mu)\n",
    "        return log_bernoullis\n",
    "    \n",
    "    def get_save_single(self, x, mu):\n",
    "        epsilon = 1e-15\n",
    "        mu_place = np.clip(mu, epsilon, 1 - epsilon)\n",
    "        return np.tensordot(x, np.log(mu_place), (1,1))\n",
    "\n",
    "    def get_Neff(self):\n",
    "        self.Neff = np.sum(self.gamma, axis=0)\n",
    "    \n",
    "    def get_mu(self, batch):\n",
    "        self.mu = np.einsum('ik,id -> kd', self.gamma, batch) / self.Neff[:, None]\n",
    "        \n",
    "    def get_pi(self):\n",
    "        self.pi = self.Neff / self.n_samples\n",
    "    \n",
    "    def predict(self, x):\n",
    "        log_bernoullis = self.get_log_bernoullis(x)\n",
    "        gamma = self.get_responsibilities(log_bernoullis)\n",
    "        return np.argmax(gamma, axis=1)\n",
    "        \n",
    "    def get_sample_log_likelihood(self, log_bernoullis):\n",
    "        return logsumexp(np.log(self.pi[None,:]) + log_bernoullis, axis=1)\n",
    "    \n",
    "    def get_log_likelihood(self, log_bernoullis):\n",
    "        return np.mean(self.get_sample_log_likelihood(log_bernoullis))\n",
    "        \n",
    "    def score(self, x):\n",
    "        log_bernoullis = self.get_log_bernoullis(x)\n",
    "        return self.get_log_likelihood(log_bernoullis)\n",
    "    \n",
    "    def score_samples(self, x):\n",
    "        log_bernoullis = self.get_log_bernoullis(x)\n",
    "        return self.get_sample_log_likelihood(log_bernoullis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fa142183-e84b-42e6-bbed-b86cf6e2dd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "# Suppress the FutureWarning\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from ucimlrepo import fetch_ucirepo   \n",
    "# fetch dataset \n",
    "zoo = fetch_ucirepo(id=111) \n",
    "\n",
    "# data (as pandas dataframes) \n",
    "X = zoo.data.features\n",
    "y = zoo.data.targets \n",
    "zoo_df = pd.merge(X, y, left_index=True, right_index=True)\n",
    "zoo_df = zoo_df.dropna()\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoded_df = zoo_df.copy()\n",
    "for column in zoo_df.columns:\n",
    "        if zoo_df[column].dtype == 'object':\n",
    "            encoded_df[column] = encoder.fit_transform(zoo_df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "95d14cb0-c53f-46b5-9c71-438696451613",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shape-mismatch for sum",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m stochastic_bmm \u001b[38;5;241m=\u001b[39m StochasticBernoulliMixture(n_components\u001b[38;5;241m=\u001b[39mn_components, max_iter\u001b[38;5;241m=\u001b[39mmax_iter, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Fit the model to the binary encoded data\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[43mstochastic_bmm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzoo_encoded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Extract cluster assignments\u001b[39;00m\n\u001b[0;32m     13\u001b[0m cluster_assignments \u001b[38;5;241m=\u001b[39m stochastic_bmm\u001b[38;5;241m.\u001b[39mpredict(zoo_df)\n",
      "Cell \u001b[1;32mIn[33], line 20\u001b[0m, in \u001b[0;36mStochasticBernoulliMixture.fit\u001b[1;34m(self, x_binary)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m x_binary\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_params()\n\u001b[1;32m---> 20\u001b[0m log_bernoullis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_log_bernoullis\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mold_logL \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_log_likelihood(log_bernoullis)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter):\n",
      "Cell \u001b[1;32mIn[33], line 78\u001b[0m, in \u001b[0;36mStochasticBernoulliMixture.get_log_bernoullis\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_log_bernoullis\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 78\u001b[0m     log_bernoullis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_save_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m     log_bernoullis \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_save_single(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mx, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmu)\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m log_bernoullis\n",
      "Cell \u001b[1;32mIn[33], line 86\u001b[0m, in \u001b[0;36mStochasticBernoulliMixture.get_save_single\u001b[1;34m(self, x, mu)\u001b[0m\n\u001b[0;32m     84\u001b[0m mu_expanded \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(mu, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Add a new axis to mu\u001b[39;00m\n\u001b[0;32m     85\u001b[0m mu_place \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(np\u001b[38;5;241m.\u001b[39mmax(mu_expanded, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-15\u001b[39m, \u001b[38;5;241m1e-15\u001b[39m, mu_expanded)\n\u001b[1;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensordot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmu_place\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\numeric.py:1099\u001b[0m, in \u001b[0;36mtensordot\u001b[1;34m(a, b, axes)\u001b[0m\n\u001b[0;32m   1097\u001b[0m             axes_b[k] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m ndb\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m equal:\n\u001b[1;32m-> 1099\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape-mismatch for sum\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;66;03m# Move the axes to sum over to the end of \"a\"\u001b[39;00m\n\u001b[0;32m   1102\u001b[0m \u001b[38;5;66;03m# and to the front of \"b\"\u001b[39;00m\n\u001b[0;32m   1103\u001b[0m notin \u001b[38;5;241m=\u001b[39m [k \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nda) \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m axes_a]\n",
      "\u001b[1;31mValueError\u001b[0m: shape-mismatch for sum"
     ]
    }
   ],
   "source": [
    "# Perform clustering\n",
    "n_components = 3  # Number of clusters\n",
    "max_iter = 100  # Maximum number of iterations\n",
    "batch_size = 50  # Size of mini-batch\n",
    "\n",
    "# Initialize the StochasticBernoulliMixture model\n",
    "stochastic_bmm = StochasticBernoulliMixture(n_components=n_components, max_iter=max_iter, batch_size=batch_size)\n",
    "\n",
    "# Fit the model to the binary encoded data\n",
    "stochastic_bmm.fit(zoo_encoded)\n",
    "\n",
    "# Extract cluster assignments\n",
    "cluster_assignments = stochastic_bmm.predict(zoo_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3211017-c62f-4f1c-bc40-b951cff19eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7331e9df-563d-4f82-bb95-2fb0cf2ed585",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
